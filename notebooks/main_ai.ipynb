{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Clone repository (Colab only - skip if running locally)\n",
        "try:\n",
        "    import google.colab\n",
        "    !git clone https://github.com/Arnabs-ops/Alzheimer-s.git\n",
        "    %cd Alzheimer-s\n",
        "    print(\"✅ Repository cloned and directory changed\")\n",
        "except:\n",
        "    print(\"ℹ️ Running locally - skipping git clone\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Install dependencies (Colab setup)\n",
        "%pip install -q xgboost lightgbm shap pyarrow category_encoders scikit-learn matplotlib seaborn joblib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Core AI Training for Alzheimer's Disease Prediction\n",
        "\n",
        "This notebook trains baseline machine learning models on preprocessed genomic data and provides comprehensive evaluation with interpretability analysis.\n",
        "\n",
        "## Features:\n",
        "- Load preprocessed NPZ data or fallback to CSV\n",
        "- Train multiple models (RF, XGBoost, LightGBM, SVM, Logistic Regression)\n",
        "- Cross-validation and performance metrics\n",
        "- SHAP analysis for interpretability\n",
        "- ROC curves and confusion matrices\n",
        "- Save best model and results\n",
        "\n",
        "## Models:\n",
        "- Random Forest (Regularized)\n",
        "- XGBoost (Regularized) \n",
        "- LightGBM (Regularized)\n",
        "- SVM (Regularized)\n",
        "- Logistic Regression (L1/L2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Colab path detection and setup\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    # Find project root (where src/ folder exists)\n",
        "    if not os.path.exists('src'):\n",
        "        # Try to find the project root\n",
        "        possible_paths = ['/content/Alzheimer-s', '/content/Alzheimer-s/Alzhemiers', '.']\n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(os.path.join(path, 'src')):\n",
        "                os.chdir(path)\n",
        "                print(f\"✅ Changed working directory to: {path}\")\n",
        "                break\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Add src to path (try multiple ways)\n",
        "current_dir = os.getcwd()\n",
        "if os.path.exists('src'):\n",
        "    sys.path.insert(0, current_dir)\n",
        "    sys.path.insert(0, os.path.join(current_dir, 'src'))\n",
        "elif os.path.exists(os.path.join('..', 'src')):\n",
        "    sys.path.insert(0, os.path.abspath('..'))\n",
        "    sys.path.insert(0, os.path.join(os.path.abspath('..'), 'src'))\n",
        "else:\n",
        "    # Try to find src folder\n",
        "    for root, dirs, files in os.walk('.'):\n",
        "        if 'src' in dirs:\n",
        "            src_path = os.path.join(root, 'src')\n",
        "            sys.path.insert(0, root)\n",
        "            sys.path.insert(0, src_path)\n",
        "            print(f\"✅ Found src at: {src_path}\")\n",
        "            break\n",
        "\n",
        "print(f\"📂 Current directory: {os.getcwd()}\")\n",
        "print(f\"📂 Python path includes: {sys.path[:3]}\")\n",
        "\n",
        "# Set thread limits for stability\n",
        "os.environ['OMP_NUM_THREADS'] = '1'\n",
        "os.environ['MKL_NUM_THREADS'] = '1'\n",
        "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
        "os.environ['NUMEXPR_MAX_THREADS'] = '1'\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "\n",
        "# Import our modules\n",
        "try:\n",
        "    from src.model import get_models, train_and_eval\n",
        "    from src.utils import load_data, split_data, ensure_dirs, save_artifacts, plot_roc_curves, plot_confusion\n",
        "    from src.interpretability import plot_shap_summary, plot_feature_importance\n",
        "    print(\"✅ Successfully imported src modules\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ Import error: {e}\")\n",
        "    print(\"💡 Trying direct imports...\")\n",
        "    # Fallback: define minimal functions inline\n",
        "    def get_models(random_state=42):\n",
        "        return {}\n",
        "    def train_and_eval(*args, **kwargs):\n",
        "        return {}\n",
        "    def ensure_dirs(path):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "    print(\"⚠️ Using fallback functions - some features may be limited\")\n",
        "\n",
        "# Create results directory\n",
        "ensure_dirs('results')\n",
        "\n",
        "print(\"✅ Setup complete - Ready for model training\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Override models for Colab with larger training values (n_estimators=1000, max_iter=1000)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "COLAB_LARGE_TRAINING = True\n",
        "\n",
        "models_large = {\n",
        "    'Random Forest': RandomForestClassifier(\n",
        "        n_estimators=1000,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        max_features='sqrt',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'XGBoost': xgb.XGBClassifier(\n",
        "        n_estimators=1000,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=0.0,\n",
        "        reg_lambda=1.0,\n",
        "        eval_metric='logloss',\n",
        "        use_label_encoder=False,\n",
        "        verbosity=0,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'LightGBM': lgb.LGBMClassifier(\n",
        "        n_estimators=1000,\n",
        "        max_depth=-1,\n",
        "        learning_rate=0.1,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_alpha=0.0,\n",
        "        reg_lambda=1.0,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'SVM': SVC(\n",
        "        C=1.0,\n",
        "        kernel='rbf',\n",
        "        gamma='scale',\n",
        "        probability=True,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'Logistic Regression': LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        C=1.0,\n",
        "        penalty='l2',\n",
        "        solver='lbfgs',\n",
        "        multi_class='ovr',\n",
        "        random_state=42\n",
        "    ),\n",
        "    'MLP': MLPClassifier(\n",
        "        hidden_layer_sizes=(128, 64),\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        alpha=0.0001,\n",
        "        learning_rate='adaptive',\n",
        "        max_iter=1000,\n",
        "        early_stopping=True,\n",
        "        validation_fraction=0.1,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# Monkey-patch get_models to return the large config if desired\n",
        "if COLAB_LARGE_TRAINING:\n",
        "    def get_models(random_state=42):\n",
        "        return models_large\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Data\n",
        "print(\"📊 Loading preprocessed data...\")\n",
        "\n",
        "# Try to load NPZ data first\n",
        "try:\n",
        "    data = np.load('data/processed/preprocessed_alz_data.npz', allow_pickle=True)\n",
        "    X_train = data['X_train']\n",
        "    X_test = data['X_test']\n",
        "    y_train = data['y_train']\n",
        "    y_test = data['y_test']\n",
        "    \n",
        "    # Handle multi-dimensional y\n",
        "    if len(y_train.shape) > 1:\n",
        "        if y_train.shape[1] == 1:\n",
        "            y_train = y_train.ravel()\n",
        "            y_test = y_test.ravel()\n",
        "        else:\n",
        "            y_train = np.argmax(y_train, axis=1)\n",
        "            y_test = np.argmax(y_test, axis=1)\n",
        "    \n",
        "    print(f\"✅ Loaded NPZ data: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"⚠️ NPZ loading failed: {e}\")\n",
        "    print(\"🔄 Loading CSV fallback...\")\n",
        "    \n",
        "    # Fallback to CSV\n",
        "    try:\n",
        "        df = load_data('data/processed/alz_clean.csv')\n",
        "        X, y = split_data(df, 'Phenotype-derived')\n",
        "        X_train, X_test, y_train, y_test = X[0], X[1], y[0], y[1]\n",
        "        print(f\"✅ Loaded CSV data: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "    except Exception as e2:\n",
        "        print(f\"❌ CSV loading failed: {e2}\")\n",
        "        print(\"🔄 Creating sample data...\")\n",
        "        \n",
        "        # Create sample data\n",
        "        np.random.seed(42)\n",
        "        X_train = np.random.randn(1000, 50)\n",
        "        X_test = np.random.randn(200, 50)\n",
        "        y_train = np.random.choice([0, 1, 2], 1000)\n",
        "        y_test = np.random.choice([0, 1, 2], 200)\n",
        "        print(f\"✅ Created sample data: Train {X_train.shape}, Test {X_test.shape}\")\n",
        "\n",
        "print(f\"📊 Target distribution: {np.bincount(y_train)}\")\n",
        "print(f\"📊 Classes: {len(np.unique(y_train))}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Models\n",
        "print(\"🤖 Training baseline models...\")\n",
        "\n",
        "# Get models\n",
        "try:\n",
        "    models = get_models(random_state=42)\n",
        "    print(f\"✅ Got {len(models)} models from get_models()\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ get_models() failed: {e}\")\n",
        "    print(\"🔄 Using models_large from previous cell...\")\n",
        "    try:\n",
        "        models = models_large\n",
        "        print(f\"✅ Using {len(models)} models from models_large\")\n",
        "    except:\n",
        "        print(\"❌ models_large not available\")\n",
        "        models = {}\n",
        "\n",
        "print(f\"📊 Models to train: {list(models.keys())}\")\n",
        "\n",
        "# Train and evaluate\n",
        "results = {}\n",
        "if not models:\n",
        "    print(\"❌ No models available to train!\")\n",
        "else:\n",
        "    try:\n",
        "        results = train_and_eval(models, X_train, y_train, X_test, y_test, cv_folds=3)\n",
        "        print(f\"✅ train_and_eval completed, got {len(results)} results\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ train_and_eval failed: {e}\")\n",
        "        print(\"🔄 Using inline training function...\")\n",
        "        \n",
        "        # Inline training function\n",
        "        from sklearn.model_selection import cross_val_score\n",
        "        from sklearn.metrics import accuracy_score\n",
        "        import warnings\n",
        "        warnings.filterwarnings('ignore')\n",
        "        \n",
        "        results = {}\n",
        "        for name, model in models.items():\n",
        "            print(f\"  Training {name}...\")\n",
        "            try:\n",
        "                # Fit model\n",
        "                model.fit(X_train, y_train)\n",
        "                \n",
        "                # Predictions\n",
        "                y_pred = model.predict(X_test)\n",
        "                acc = accuracy_score(y_test, y_pred)\n",
        "                \n",
        "                # Cross-validation\n",
        "                cv_scores = cross_val_score(model, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "                \n",
        "                results[name] = {\n",
        "                    'model': model,\n",
        "                    'pred': y_pred,\n",
        "                    'accuracy': acc,\n",
        "                    'cv_mean': cv_scores.mean(),\n",
        "                    'cv_std': cv_scores.std()\n",
        "                }\n",
        "                print(f\"    ✅ Accuracy: {acc:.4f}, CV: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
        "            except Exception as e2:\n",
        "                print(f\"    ❌ {name} failed: {e2}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "print(f\"\\n📊 Total results collected: {len(results)}\")\n",
        "print(f\"📊 Results keys: {list(results.keys())}\")\n",
        "\n",
        "print(\"\\n📊 Model Performance Summary:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Create summary DataFrame\n",
        "if results:\n",
        "    summary_data = []\n",
        "    for name, res in results.items():\n",
        "        print(f\"Processing {name}: {type(res)}, keys: {res.keys() if isinstance(res, dict) else 'not dict'}\")\n",
        "        if isinstance(res, dict) and 'accuracy' in res:\n",
        "            summary_data.append({\n",
        "                'Model': name,\n",
        "                'Accuracy': res['accuracy'],\n",
        "                'CV_Mean': res['cv_mean'],\n",
        "                'CV_Std': res['cv_std']\n",
        "            })\n",
        "        else:\n",
        "            print(f\"  ⚠️ Skipping {name} - invalid result format\")\n",
        "    \n",
        "    if summary_data:\n",
        "        summary_df = pd.DataFrame(summary_data)\n",
        "        summary_df = summary_df.sort_values('Accuracy', ascending=False)\n",
        "        print(summary_df.to_string(index=False))\n",
        "    else:\n",
        "        print(\"⚠️ No valid results to display\")\n",
        "        print(f\"Debug: summary_data length = {len(summary_data)}\")\n",
        "        summary_df = pd.DataFrame()  # Empty dataframe\n",
        "else:\n",
        "    print(\"⚠️ No models were trained successfully\")\n",
        "    print(\"Debug: results is empty or None\")\n",
        "    summary_df = pd.DataFrame()  # Empty dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizations\n",
        "if not summary_df.empty and len(summary_df) > 0:\n",
        "    print(\"📈 Generating visualizations...\")\n",
        "    \n",
        "    # Accuracy comparison\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    summary_df.plot(x='Model', y='Accuracy', kind='bar', ax=plt.gca())\n",
        "    plt.title('Model Accuracy Comparison')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.ylabel('Accuracy')\n",
        "    \n",
        "    # CV scores with error bars\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.errorbar(range(len(summary_df)), summary_df['CV_Mean'], \n",
        "                 yerr=summary_df['CV_Std'], fmt='o', capsize=5)\n",
        "    plt.xticks(range(len(summary_df)), summary_df['Model'], rotation=45)\n",
        "    plt.title('Cross-Validation Scores')\n",
        "    plt.ylabel('CV Score')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # ROC Curves (if function available)\n",
        "    if results and 'plot_roc_curves' in globals():\n",
        "        try:\n",
        "            print(\"\\n📊 ROC Curves:\")\n",
        "            plot_roc_curves(results, y_test)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ ROC curves failed: {e}\")\n",
        "    \n",
        "    # Confusion Matrix for best model\n",
        "    if results:\n",
        "        try:\n",
        "            best_model_name = summary_df.iloc[0]['Model']\n",
        "            if best_model_name in results and 'model' in results[best_model_name]:\n",
        "                best_model = results[best_model_name]['model']\n",
        "                best_pred = results[best_model_name]['pred']\n",
        "                \n",
        "                if 'plot_confusion' in globals():\n",
        "                    print(f\"\\n📊 Confusion Matrix - {best_model_name}:\")\n",
        "                    plot_confusion(y_test, best_pred, normalize=True)\n",
        "                else:\n",
        "                    # Fallback confusion matrix\n",
        "                    from sklearn.metrics import confusion_matrix\n",
        "                    cm = confusion_matrix(y_test, best_pred)\n",
        "                    plt.figure(figsize=(8, 6))\n",
        "                    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "                    plt.title(f'Confusion Matrix - {best_model_name}')\n",
        "                    plt.xlabel('Predicted')\n",
        "                    plt.ylabel('True')\n",
        "                    plt.show()\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Confusion matrix failed: {e}\")\n",
        "else:\n",
        "    print(\"⚠️ No results available for visualization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SHAP Analysis (for tree-based models)\n",
        "print(\"🔍 SHAP Analysis for interpretability...\")\n",
        "\n",
        "try:\n",
        "    import shap\n",
        "    \n",
        "    # Analyze tree-based models\n",
        "    tree_models = ['Random Forest', 'XGBoost', 'LightGBM']\n",
        "    \n",
        "    for model_name in tree_models:\n",
        "        if model_name in results:\n",
        "            print(f\"\\n🔍 Analyzing {model_name}...\")\n",
        "            \n",
        "            model = results[model_name]['model']\n",
        "            \n",
        "            # Create SHAP explainer\n",
        "            if hasattr(model, 'predict_proba'):\n",
        "                explainer = shap.TreeExplainer(model)\n",
        "                shap_values = explainer.shap_values(X_test[:100])  # Sample for speed\n",
        "                \n",
        "                # Summary plot\n",
        "                plt.figure(figsize=(10, 6))\n",
        "                shap.summary_plot(shap_values, X_test[:100], show=False)\n",
        "                plt.title(f'SHAP Summary - {model_name}')\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "                \n",
        "                print(f\"✅ SHAP analysis complete for {model_name}\")\n",
        "            else:\n",
        "                print(f\"⚠️ {model_name} doesn't support SHAP analysis\")\n",
        "                \n",
        "except ImportError:\n",
        "    print(\"⚠️ SHAP not installed. Install with: pip install shap\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ SHAP analysis failed: {e}\")\n",
        "\n",
        "# Feature Importance for tree models\n",
        "print(\"\\n📊 Feature Importance Analysis:\")\n",
        "for model_name in ['Random Forest', 'XGBoost', 'LightGBM']:\n",
        "    if model_name in results:\n",
        "        plot_feature_importance(results[model_name]['model'], model_name, top_n=20)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save Results\n",
        "if not summary_df.empty and len(results) > 0:\n",
        "    print(\"💾 Saving results and best model...\")\n",
        "    \n",
        "    # Save metrics CSV\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    csv_path = f'results/model_summary_{timestamp}.csv'\n",
        "    summary_df.to_csv(csv_path, index=False)\n",
        "    print(f\"✅ Metrics saved to: {csv_path}\")\n",
        "    \n",
        "    # Save best model\n",
        "    try:\n",
        "        if len(summary_df) > 0 and not summary_df.empty:\n",
        "            best_model_name = summary_df.iloc[0]['Model']\n",
        "            if best_model_name in results and 'model' in results[best_model_name]:\n",
        "                best_model = results[best_model_name]['model']\n",
        "                model_path = f'results/best_model_{timestamp}.pkl'\n",
        "                \n",
        "                import joblib\n",
        "                joblib.dump(best_model, model_path)\n",
        "                print(f\"✅ Best model ({best_model_name}) saved to: {model_path}\")\n",
        "            else:\n",
        "                print(f\"⚠️ Best model '{best_model_name}' not found in results\")\n",
        "        else:\n",
        "            print(\"⚠️ summary_df is empty, cannot save best model\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not save best model: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "    \n",
        "    # Save detailed results JSON\n",
        "    try:\n",
        "        import json\n",
        "        detailed_results = {}\n",
        "        for name, res in results.items():\n",
        "            if isinstance(res, dict) and 'accuracy' in res:\n",
        "                detailed_results[name] = {\n",
        "                    'accuracy': float(res['accuracy']),\n",
        "                    'cv_mean': float(res['cv_mean']),\n",
        "                    'cv_std': float(res['cv_std'])\n",
        "                }\n",
        "        \n",
        "        if detailed_results:\n",
        "            json_path = f'results/detailed_results_{timestamp}.json'\n",
        "            with open(json_path, 'w') as f:\n",
        "                json.dump(detailed_results, f, indent=2)\n",
        "            print(f\"✅ Detailed results saved to: {json_path}\")\n",
        "        else:\n",
        "            print(\"⚠️ No valid results to save in JSON\")\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not save JSON: {e}\")\n",
        "    \n",
        "    print(f\"\\n🎉 Training complete!\")\n",
        "    if len(summary_df) > 0 and not summary_df.empty:\n",
        "        print(f\"🏆 Best model: {summary_df.iloc[0]['Model']} (Accuracy: {summary_df.iloc[0]['Accuracy']:.4f})\")\n",
        "    print(f\"📊 All results saved to results/ directory\")\n",
        "else:\n",
        "    print(\"⚠️ No results to save\")\n",
        "    print(f\"Debug: summary_df.empty = {summary_df.empty if 'summary_df' in locals() else 'not defined'}\")\n",
        "    print(f\"Debug: len(results) = {len(results) if 'results' in locals() else 'not defined'}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Alzheimer's Disease Detection & Analysis\n",
        "## Hack4Health Hackathon Project\n",
        "\n",
        "**Goal**: Build machine learning models to support early detection, progression forecasting, and interpretability of Alzheimer's Disease risk using real biomedical data.\n",
        "\n",
        "### Project Objectives:\n",
        "1. **Early Detection**: Identify Alzheimer's Disease in its early stages\n",
        "2. **Progression Forecasting**: Predict disease progression patterns  \n",
        "3. **Interpretability**: Understand factors contributing to disease risk\n",
        "\n",
        "### Dataset Information:\n",
        "- **Source**: Real, de-identified biomedical data\n",
        "- **Location**: `../data/raw/` directory\n",
        "- **Privacy**: All data is de-identified and compliant with usage guidelines\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Machine Learning Libraries\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Model Interpretability\n",
        "import shap\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Configure pandas display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(f\"üìä NumPy version: {np.__version__}\")\n",
        "print(f\"üêº Pandas version: {pd.__version__}\")\n",
        "print(f\"üìà Matplotlib version: {plt.matplotlib.__version__}\")\n",
        "print(f\"üé® Seaborn version: {sns.__version__}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading and Initial Exploration\n",
        "\n",
        "**Instructions**: \n",
        "1. Place your downloaded datasets in the `../data/raw/` directory\n",
        "2. Update the file paths below to match your actual dataset filenames\n",
        "3. Modify the data loading code based on your dataset format (CSV, Excel, etc.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Loading - Genomic Alzheimer's Disease Variants\n",
        "data_path = \"../data/raw/\"\n",
        "\n",
        "# Load the genomic datasets\n",
        "print(\"üß¨ Loading Alzheimer's Disease genomic datasets...\")\n",
        "\n",
        "# Load TSV file (variant data with positions)\n",
        "df_variants = pd.read_csv(f\"{data_path}advp.hg38.tsv\", sep='\\t', comment='#')\n",
        "print(f\"‚úÖ Loaded TSV dataset: {df_variants.shape}\")\n",
        "\n",
        "# Load BED file (genomic regions)\n",
        "df_regions = pd.read_csv(f\"{data_path}advp.hg38.bed\", sep='\\t', comment='#')\n",
        "print(f\"‚úÖ Loaded BED dataset: {df_regions.shape}\")\n",
        "\n",
        "# Display basic information about the datasets\n",
        "print(f\"\\nüìä TSV Dataset Info:\")\n",
        "print(f\"   Shape: {df_variants.shape}\")\n",
        "print(f\"   Columns: {list(df_variants.columns)}\")\n",
        "print(f\"   Memory usage: {df_variants.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "print(f\"\\nüìä BED Dataset Info:\")\n",
        "print(f\"   Shape: {df_regions.shape}\")\n",
        "print(f\"   Columns: {list(df_regions.columns)}\")\n",
        "print(f\"   Memory usage: {df_regions.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "\n",
        "# Display first few rows\n",
        "print(f\"\\nüîç First 5 rows of TSV dataset:\")\n",
        "print(df_variants.head())\n",
        "\n",
        "print(f\"\\nüîç First 5 rows of BED dataset:\")\n",
        "print(df_regions.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Genomic Data Analysis Functions\n",
        "\n",
        "def analyze_genomic_variants(df_variants):\n",
        "    \"\"\"\n",
        "    Analyze the genomic variants dataset for Alzheimer's Disease\n",
        "    \"\"\"\n",
        "    print(\"üß¨ GENOMIC VARIANTS ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Basic statistics\n",
        "    print(f\"üìä Dataset Overview:\")\n",
        "    print(f\"   Total variants: {len(df_variants):,}\")\n",
        "    print(f\"   Unique chromosomes: {df_variants['#dbSNP_hg38_chr'].nunique()}\")\n",
        "    print(f\"   Unique SNPs: {df_variants['Top SNP'].nunique()}\")\n",
        "    print(f\"   Unique genes: {df_variants['nearest_gene_symb'].nunique()}\")\n",
        "    \n",
        "    # Chromosome distribution\n",
        "    print(f\"\\nüìà Chromosome Distribution:\")\n",
        "    chr_counts = df_variants['#dbSNP_hg38_chr'].value_counts().sort_index()\n",
        "    print(chr_counts)\n",
        "    \n",
        "    # Study types\n",
        "    print(f\"\\nüî¨ Study Types:\")\n",
        "    study_types = df_variants['Study type'].value_counts()\n",
        "    print(study_types)\n",
        "    \n",
        "    # Phenotypes\n",
        "    print(f\"\\nüéØ Phenotypes:\")\n",
        "    phenotypes = df_variants['Phenotype'].value_counts()\n",
        "    print(phenotypes.head(10))\n",
        "    \n",
        "    # P-value distribution\n",
        "    print(f\"\\nüìä P-value Statistics:\")\n",
        "    p_values = pd.to_numeric(df_variants['P-value'], errors='coerce')\n",
        "    print(f\"   Significant variants (p < 0.05): {(p_values < 0.05).sum():,}\")\n",
        "    print(f\"   Highly significant (p < 0.001): {(p_values < 0.001).sum():,}\")\n",
        "    print(f\"   Genome-wide significant (p < 5e-8): {(p_values < 5e-8).sum():,}\")\n",
        "    \n",
        "    return {\n",
        "        'total_variants': len(df_variants),\n",
        "        'unique_snps': df_variants['Top SNP'].nunique(),\n",
        "        'unique_genes': df_variants['nearest_gene_symb'].nunique(),\n",
        "        'significant_variants': (p_values < 0.05).sum(),\n",
        "        'chr_counts': chr_counts,\n",
        "        'study_types': study_types,\n",
        "        'phenotypes': phenotypes\n",
        "    }\n",
        "\n",
        "def create_genomic_visualizations(df_variants):\n",
        "    \"\"\"\n",
        "    Create visualizations for genomic data\n",
        "    \"\"\"\n",
        "    print(\"üìä Creating genomic visualizations...\")\n",
        "    \n",
        "    # Convert P-values to numeric\n",
        "    df_variants['P_value_numeric'] = pd.to_numeric(df_variants['P-value'], errors='coerce')\n",
        "    \n",
        "    # 1. Chromosome distribution\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    chr_counts = df_variants['#dbSNP_hg38_chr'].value_counts().sort_index()\n",
        "    plt.bar(chr_counts.index, chr_counts.values, color='skyblue')\n",
        "    plt.title('Distribution of Variants Across Chromosomes')\n",
        "    plt.xlabel('Chromosome')\n",
        "    plt.ylabel('Number of Variants')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 2. P-value distribution (Manhattan plot style)\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    \n",
        "    # Create Manhattan plot\n",
        "    chr_positions = {}\n",
        "    cumulative_pos = 0\n",
        "    \n",
        "    for chr_name in sorted(df_variants['#dbSNP_hg38_chr'].unique()):\n",
        "        chr_data = df_variants[df_variants['#dbSNP_hg38_chr'] == chr_name]\n",
        "        chr_positions[chr_name] = cumulative_pos\n",
        "        cumulative_pos += chr_data['#dbSNP_hg38_position'].max()\n",
        "    \n",
        "    colors = ['red' if i % 2 == 0 else 'blue' for i in range(len(chr_positions))]\n",
        "    \n",
        "    for i, (chr_name, start_pos) in enumerate(chr_positions.items()):\n",
        "        chr_data = df_variants[df_variants['#dbSNP_hg38_chr'] == chr_name]\n",
        "        x_pos = start_pos + chr_data['#dbSNP_hg38_position']\n",
        "        y_values = -np.log10(chr_data['P_value_numeric'].fillna(1))\n",
        "        \n",
        "        plt.scatter(x_pos, y_values, c=colors[i], alpha=0.6, s=20)\n",
        "    \n",
        "    plt.axhline(y=-np.log10(5e-8), color='red', linestyle='--', alpha=0.7, label='Genome-wide significance')\n",
        "    plt.axhline(y=-np.log10(0.05), color='orange', linestyle='--', alpha=0.7, label='Nominal significance')\n",
        "    \n",
        "    plt.title('Manhattan Plot - Alzheimer\\'s Disease Variants')\n",
        "    plt.xlabel('Genomic Position')\n",
        "    plt.ylabel('-log10(P-value)')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 3. Study type distribution\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    study_counts = df_variants['Study type'].value_counts()\n",
        "    plt.pie(study_counts.values, labels=study_counts.index, autopct='%1.1f%%')\n",
        "    plt.title('Distribution of Study Types')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # 4. Top genes by variant count\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    top_genes = df_variants['nearest_gene_symb'].value_counts().head(15)\n",
        "    plt.barh(range(len(top_genes)), top_genes.values)\n",
        "    plt.yticks(range(len(top_genes)), top_genes.index)\n",
        "    plt.xlabel('Number of Variants')\n",
        "    plt.title('Top 15 Genes by Number of Associated Variants')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_phenotype_associations(df_variants):\n",
        "    \"\"\"\n",
        "    Analyze phenotype associations in the genomic data\n",
        "    \"\"\"\n",
        "    print(\"üéØ PHENOTYPE ASSOCIATION ANALYSIS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Group by phenotype\n",
        "    phenotype_groups = df_variants.groupby('Phenotype')\n",
        "    \n",
        "    print(f\"üìä Phenotype Summary:\")\n",
        "    print(f\"   Total phenotypes: {len(phenotype_groups)}\")\n",
        "    \n",
        "    # Top phenotypes by variant count\n",
        "    phenotype_counts = phenotype_groups.size().sort_values(ascending=False)\n",
        "    print(f\"\\nüîù Top 10 Phenotypes by Variant Count:\")\n",
        "    print(phenotype_counts.head(10))\n",
        "    \n",
        "    # AD-specific analysis\n",
        "    ad_variants = df_variants[df_variants['Phenotype'] == 'AD']\n",
        "    print(f\"\\nüß† AD-Specific Analysis:\")\n",
        "    print(f\"   AD variants: {len(ad_variants):,}\")\n",
        "    print(f\"   AD-associated genes: {ad_variants['nearest_gene_symb'].nunique()}\")\n",
        "    \n",
        "    # Significant AD variants\n",
        "    ad_p_values = pd.to_numeric(ad_variants['P-value'], errors='coerce')\n",
        "    significant_ad = ad_variants[ad_p_values < 0.05]\n",
        "    print(f\"   Significant AD variants (p < 0.05): {len(significant_ad):,}\")\n",
        "    \n",
        "    # Top AD-associated genes\n",
        "    print(f\"\\nüß¨ Top AD-Associated Genes:\")\n",
        "    ad_gene_counts = ad_variants['nearest_gene_symb'].value_counts().head(10)\n",
        "    print(ad_gene_counts)\n",
        "    \n",
        "    return {\n",
        "        'phenotype_counts': phenotype_counts,\n",
        "        'ad_variants': len(ad_variants),\n",
        "        'ad_genes': ad_variants['nearest_gene_symb'].nunique(),\n",
        "        'significant_ad': len(significant_ad),\n",
        "        'top_ad_genes': ad_gene_counts\n",
        "    }\n",
        "\n",
        "print(\"üß¨ Genomic analysis functions loaded and ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run Genomic Analysis\n",
        "print(\"üß¨ Starting Genomic Analysis...\")\n",
        "\n",
        "# Analyze the variants dataset\n",
        "variant_stats = analyze_genomic_variants(df_variants)\n",
        "\n",
        "# Create visualizations\n",
        "create_genomic_visualizations(df_variants)\n",
        "\n",
        "# Analyze phenotype associations\n",
        "phenotype_stats = analyze_phenotype_associations(df_variants)\n",
        "\n",
        "print(\"\\n‚úÖ Genomic analysis completed!\")\n",
        "print(\"üìä Key findings:\")\n",
        "print(f\"   ‚Ä¢ Total variants analyzed: {variant_stats['total_variants']:,}\")\n",
        "print(f\"   ‚Ä¢ Significant variants: {variant_stats['significant_variants']:,}\")\n",
        "print(f\"   ‚Ä¢ AD-specific variants: {phenotype_stats['ad_variants']:,}\")\n",
        "print(f\"   ‚Ä¢ AD-associated genes: {phenotype_stats['ad_genes']:,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Genomic Data Preprocessing for Machine Learning\n",
        "\n",
        "def prepare_genomic_features(df_variants):\n",
        "    \"\"\"\n",
        "    Prepare genomic features for machine learning\n",
        "    \"\"\"\n",
        "    print(\"üîß Preparing genomic features for ML...\")\n",
        "    \n",
        "    # Create a copy for processing\n",
        "    df_ml = df_variants.copy()\n",
        "    \n",
        "    # Convert P-values to numeric and create significance features\n",
        "    df_ml['P_value_numeric'] = pd.to_numeric(df_ml['P-value'], errors='coerce')\n",
        "    df_ml['is_significant'] = (df_ml['P_value_numeric'] < 0.05).astype(int)\n",
        "    df_ml['is_highly_significant'] = (df_ml['P_value_numeric'] < 0.001).astype(int)\n",
        "    df_ml['is_genome_wide_significant'] = (df_ml['P_value_numeric'] < 5e-8).astype(int)\n",
        "    \n",
        "    # Create log-transformed P-values\n",
        "    df_ml['log_p_value'] = -np.log10(df_ml['P_value_numeric'].fillna(1))\n",
        "    \n",
        "    # Extract chromosome number for numerical analysis\n",
        "    df_ml['chr_numeric'] = df_ml['#dbSNP_hg38_chr'].str.replace('chr', '').astype(str)\n",
        "    df_ml['chr_numeric'] = pd.to_numeric(df_ml['chr_numeric'], errors='coerce')\n",
        "    \n",
        "    # Create study type features\n",
        "    study_type_dummies = pd.get_dummies(df_ml['Study type'], prefix='study_type')\n",
        "    df_ml = pd.concat([df_ml, study_type_dummies], axis=1)\n",
        "    \n",
        "    # Create phenotype features\n",
        "    phenotype_dummies = pd.get_dummies(df_ml['Phenotype'], prefix='phenotype')\n",
        "    df_ml = pd.concat([df_ml, phenotype_dummies], axis=1)\n",
        "    \n",
        "    # Create consequence type features\n",
        "    consequence_dummies = pd.get_dummies(df_ml['most_severe_consequence'], prefix='consequence')\n",
        "    df_ml = pd.concat([df_ml, consequence_dummies], axis=1)\n",
        "    \n",
        "    # Create gene-based features\n",
        "    df_ml['gene_variant_count'] = df_ml.groupby('nearest_gene_symb')['nearest_gene_symb'].transform('count')\n",
        "    \n",
        "    # Create chromosome-based features\n",
        "    df_ml['chr_variant_count'] = df_ml.groupby('#dbSNP_hg38_chr')['#dbSNP_hg38_chr'].transform('count')\n",
        "    \n",
        "    print(f\"   ‚úÖ Created {df_ml.shape[1]} features from {df_variants.shape[1]} original columns\")\n",
        "    \n",
        "    return df_ml\n",
        "\n",
        "def create_ad_prediction_dataset(df_ml):\n",
        "    \"\"\"\n",
        "    Create dataset for AD prediction based on genomic variants\n",
        "    \"\"\"\n",
        "    print(\"üéØ Creating AD prediction dataset...\")\n",
        "    \n",
        "    # Focus on AD-related variants\n",
        "    ad_related = df_ml[\n",
        "        (df_ml['Phenotype'] == 'AD') | \n",
        "        (df_ml['Phenotype-derived'] == 'AD') |\n",
        "        (df_ml.get('phenotype_AD', 0) == 1)\n",
        "    ].copy()\n",
        "    \n",
        "    print(f\"   üìä AD-related variants: {len(ad_related):,}\")\n",
        "    \n",
        "    # Create binary target: significant AD variants vs non-significant\n",
        "    ad_related['is_ad_significant'] = (\n",
        "        (ad_related['Phenotype'] == 'AD') & \n",
        "        (ad_related['is_significant'] == 1)\n",
        "    ).astype(int)\n",
        "    \n",
        "    # Select features for ML\n",
        "    feature_cols = [\n",
        "        'P_value_numeric', 'log_p_value', 'chr_numeric', 'chr_variant_count',\n",
        "        'gene_variant_count', 'is_significant', 'is_highly_significant', \n",
        "        'is_genome_wide_significant'\n",
        "    ]\n",
        "    \n",
        "    # Add study type features\n",
        "    study_cols = [col for col in ad_related.columns if col.startswith('study_type_')]\n",
        "    feature_cols.extend(study_cols)\n",
        "    \n",
        "    # Add consequence features\n",
        "    consequence_cols = [col for col in ad_related.columns if col.startswith('consequence_')]\n",
        "    feature_cols.extend(consequence_cols)\n",
        "    \n",
        "    # Filter to existing columns\n",
        "    feature_cols = [col for col in feature_cols if col in ad_related.columns]\n",
        "    \n",
        "    X = ad_related[feature_cols].fillna(0)\n",
        "    y = ad_related['is_ad_significant']\n",
        "    \n",
        "    print(f\"   üìà Features: {X.shape[1]}\")\n",
        "    print(f\"   üéØ Target distribution: {y.value_counts().to_dict()}\")\n",
        "    \n",
        "    return X, y, ad_related\n",
        "\n",
        "# Prepare the data\n",
        "df_ml_ready = prepare_genomic_features(df_variants)\n",
        "X_genomic, y_genomic, ad_data = create_ad_prediction_dataset(df_ml_ready)\n",
        "\n",
        "print(\"‚úÖ Genomic data preprocessing completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Machine Learning Analysis on Genomic Data\n",
        "\n",
        "# Check if we have enough data for ML\n",
        "if len(X_genomic) > 100 and y_genomic.sum() > 10:\n",
        "    print(\"ü§ñ Running Machine Learning Analysis on Genomic Data...\")\n",
        "    \n",
        "    # Split the data\n",
        "    X_train_genomic, X_test_genomic, y_train_genomic, y_test_genomic = train_test_split(\n",
        "        X_genomic, y_genomic, test_size=0.2, random_state=42, stratify=y_genomic\n",
        "    )\n",
        "    \n",
        "    print(f\"   üìä Training set: {X_train_genomic.shape}\")\n",
        "    print(f\"   üìä Test set: {X_test_genomic.shape}\")\n",
        "    \n",
        "    # Train and evaluate models\n",
        "    genomic_results = train_and_evaluate_models(\n",
        "        X_train_genomic, X_test_genomic, y_train_genomic, y_test_genomic\n",
        "    )\n",
        "    \n",
        "    # Create model comparison plots\n",
        "    plot_model_comparison(genomic_results)\n",
        "    \n",
        "    # Generate detailed reports\n",
        "    detailed_model_report(genomic_results, y_test_genomic)\n",
        "    \n",
        "    # Create final summary\n",
        "    best_model_name, best_model, summary_df = create_final_summary(genomic_results)\n",
        "    \n",
        "    # Feature importance analysis\n",
        "    feature_importance_df = feature_importance_analysis(X_train_genomic, y_train_genomic)\n",
        "    \n",
        "    # Generate insights\n",
        "    generate_insights_report(summary_df, feature_importance_df)\n",
        "    \n",
        "    print(\"‚úÖ Genomic ML analysis completed!\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Insufficient data for machine learning analysis\")\n",
        "    print(f\"   Total samples: {len(X_genomic)}\")\n",
        "    print(f\"   Positive samples: {y_genomic.sum()}\")\n",
        "    print(\"   Need at least 100 samples and 10 positive cases\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Load Preprocessed NPZ Dataset\n",
        "\n",
        "We'll inspect the contents of `preprocessed_alz_data.npz` (keys, shapes, and dtypes) and optionally plug it into the ML pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect NPZ contents\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "npz_path = \"../data/raw/preprocessed_alz_data.npz\"\n",
        "\n",
        "if os.path.exists(npz_path):\n",
        "    print(f\"üì¶ Loading NPZ: {npz_path}\")\n",
        "    data = np.load(npz_path, allow_pickle=True)\n",
        "    keys = list(data.keys())\n",
        "    print(f\"üîë Keys: {keys}\")\n",
        "    \n",
        "    # Show shapes and dtypes\n",
        "    for k in keys:\n",
        "        arr = data[k]\n",
        "        shape = getattr(arr, 'shape', None)\n",
        "        dtype = getattr(arr, 'dtype', type(arr))\n",
        "        print(f\" - {k}: shape={shape}, dtype={dtype}\")\n",
        "    \n",
        "    # Heuristics to find features/labels\n",
        "    X_key = next((k for k in keys if k.lower() in [\"x\",\"features\",\"X\",\"X_train\",\"X_test\"]) , None)\n",
        "    y_key = next((k for k in keys if k.lower() in [\"y\",\"labels\",\"target\",\"y_train\",\"y_test\"]) , None)\n",
        "    \n",
        "    if X_key is None:\n",
        "        # fallback: pick first array-like\n",
        "        for k in keys:\n",
        "            if hasattr(data[k], 'shape'):\n",
        "                X_key = k\n",
        "                break\n",
        "    \n",
        "    print(f\"\\nüìå Selected feature key: {X_key}\")\n",
        "    print(f\"üìå Selected target key: {y_key}\")\n",
        "else:\n",
        "    print(f\"‚ùå NPZ not found at {npz_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Train ML models on NPZ data if keys found\n",
        "try:\n",
        "    if 'data' in locals() and X_key is not None and y_key is not None:\n",
        "        X_npz = data[X_key]\n",
        "        y_npz = data[y_key]\n",
        "        \n",
        "        print(f\"\\n‚úÖ Using NPZ dataset: X={X_npz.shape}, y={y_npz.shape}\")\n",
        "        \n",
        "        # If y is not 1D, flatten\n",
        "        if len(y_npz.shape) > 1 and y_npz.shape[1] == 1:\n",
        "            y_npz = y_npz.ravel()\n",
        "        \n",
        "        # Train-test split\n",
        "        X_train_npz, X_test_npz, y_train_npz, y_test_npz = train_test_split(\n",
        "            X_npz, y_npz, test_size=0.2, random_state=42, stratify=y_npz if len(np.unique(y_npz)) > 1 else None\n",
        "        )\n",
        "        \n",
        "        # Train models\n",
        "        npz_results = train_and_evaluate_models(X_train_npz, X_test_npz, y_train_npz, y_test_npz)\n",
        "        plot_model_comparison(npz_results)\n",
        "        detailed_model_report(npz_results, y_test_npz)\n",
        "        \n",
        "        best_model_name, best_model, summary_df = create_final_summary(npz_results)\n",
        "        generate_insights_report(summary_df)\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  Could not determine feature/label keys in NPZ. Please set X_key and y_key manually.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error running ML on NPZ data: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save NPZ results and best model\n",
        "import os, json, joblib\n",
        "from datetime import datetime\n",
        "\n",
        "results_dir = \"../results/\"\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "try:\n",
        "    if 'npz_results' in locals():\n",
        "        # Save summary CSV and JSON\n",
        "        _, _, summary_df = create_final_summary(npz_results)\n",
        "        summary_path = os.path.join(results_dir, f\"npz_model_summary_{timestamp}.csv\")\n",
        "        summary_df.to_csv(summary_path, index=False)\n",
        "        \n",
        "        simple = {k: {m: float(v[m]) if v[m] is not None else None for m in ['accuracy','auc','cv_mean','cv_std']} for k, v in npz_results.items()}\n",
        "        json_path = os.path.join(results_dir, f\"npz_all_results_{timestamp}.json\")\n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump(simple, f, indent=2)\n",
        "        \n",
        "        # Save best model\n",
        "        best_model_name = max(npz_results.items(), key=lambda x: x[1]['accuracy'])[0]\n",
        "        best_model = npz_results[best_model_name]['model']\n",
        "        model_path = os.path.join(results_dir, f\"npz_best_model_{best_model_name}_{timestamp}.pkl\")\n",
        "        joblib.dump(best_model, model_path)\n",
        "        \n",
        "        print(f\"üíæ Saved: {summary_path}\")\n",
        "        print(f\"üíæ Saved: {json_path}\")\n",
        "        print(f\"üíæ Saved: {model_path}\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  npz_results not found. Run the NPZ ML cell first.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error saving NPZ results: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. MRI Scan Data Analysis (Parquet Files)\n",
        "\n",
        "This section handles the MRI scan data from the parquet files (`train.parquet` and `test.parquet`) which complement the genomic data for comprehensive Alzheimer's analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and analyze MRI scan data from parquet files\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load parquet files\n",
        "train_path = \"../data/raw/train.parquet\"\n",
        "test_path = \"../data/raw/test.parquet\"\n",
        "\n",
        "print(\"üß† Loading MRI scan datasets...\")\n",
        "\n",
        "try:\n",
        "    df_train = pd.read_parquet(train_path)\n",
        "    df_test = pd.read_parquet(test_path)\n",
        "    \n",
        "    print(f\"‚úÖ Train dataset: {df_train.shape}\")\n",
        "    print(f\"‚úÖ Test dataset: {df_test.shape}\")\n",
        "    \n",
        "    # Display basic information\n",
        "    print(f\"\\nüìä Train Dataset Info:\")\n",
        "    print(f\"   Shape: {df_train.shape}\")\n",
        "    print(f\"   Columns: {list(df_train.columns)}\")\n",
        "    print(f\"   Memory usage: {df_train.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    \n",
        "    print(f\"\\nüìä Test Dataset Info:\")\n",
        "    print(f\"   Shape: {df_test.shape}\")\n",
        "    print(f\"   Columns: {list(df_test.columns)}\")\n",
        "    print(f\"   Memory usage: {df_test.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    \n",
        "    # Display first few rows\n",
        "    print(f\"\\nüîç First 5 rows of train dataset:\")\n",
        "    print(df_train.head())\n",
        "    \n",
        "    print(f\"\\nüîç First 5 rows of test dataset:\")\n",
        "    print(df_test.head())\n",
        "    \n",
        "    # Check for target variable\n",
        "    if 'target' in df_train.columns or 'label' in df_train.columns or 'diagnosis' in df_train.columns:\n",
        "        target_col = next(col for col in ['target', 'label', 'diagnosis'] if col in df_train.columns)\n",
        "        print(f\"\\nüéØ Target variable found: {target_col}\")\n",
        "        print(f\"   Distribution: {df_train[target_col].value_counts().to_dict()}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading parquet files: {e}\")\n",
        "    print(\"   Make sure train.parquet and test.parquet are in data/raw/ directory\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MRI Data Analysis and ML Pipeline\n",
        "if 'df_train' in locals() and 'df_test' in locals():\n",
        "    print(\"üß† Running MRI Data Analysis...\")\n",
        "    \n",
        "    # Find target column\n",
        "    target_candidates = ['target', 'label', 'diagnosis', 'class', 'y']\n",
        "    target_col = None\n",
        "    for col in target_candidates:\n",
        "        if col in df_train.columns:\n",
        "            target_col = col\n",
        "            break\n",
        "    \n",
        "    if target_col:\n",
        "        print(f\"üéØ Using target column: {target_col}\")\n",
        "        \n",
        "        # Prepare features and target\n",
        "        feature_cols = [col for col in df_train.columns if col != target_col]\n",
        "        X_train_mri = df_train[feature_cols]\n",
        "        y_train_mri = df_train[target_col]\n",
        "        \n",
        "        # Handle test data (might not have target)\n",
        "        if target_col in df_test.columns:\n",
        "            X_test_mri = df_test[feature_cols]\n",
        "            y_test_mri = df_test[target_col]\n",
        "        else:\n",
        "            X_test_mri = df_test[feature_cols]\n",
        "            y_test_mri = None\n",
        "            print(\"‚ö†Ô∏è  Test data has no target column - using for prediction only\")\n",
        "        \n",
        "        print(f\"üìä Training features: {X_train_mri.shape}\")\n",
        "        print(f\"üìä Training target: {y_train_mri.shape}\")\n",
        "        print(f\"üìä Test features: {X_test_mri.shape}\")\n",
        "        \n",
        "        # Handle missing values\n",
        "        X_train_mri = X_train_mri.fillna(X_train_mri.median())\n",
        "        X_test_mri = X_test_mri.fillna(X_train_mri.median())\n",
        "        \n",
        "        # Train models on MRI data\n",
        "        if y_test_mri is not None:\n",
        "            print(\"ü§ñ Training models on MRI data...\")\n",
        "            mri_results = train_and_evaluate_models(X_train_mri, X_test_mri, y_train_mri, y_test_mri)\n",
        "            plot_model_comparison(mri_results)\n",
        "            detailed_model_report(mri_results, y_test_mri)\n",
        "            \n",
        "            best_model_name, best_model, summary_df = create_final_summary(mri_results)\n",
        "            generate_insights_report(summary_df)\n",
        "            \n",
        "            print(\"‚úÖ MRI ML analysis completed!\")\n",
        "        else:\n",
        "            print(\"üìù Test data ready for prediction (no ground truth available)\")\n",
        "            \n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No target column found in MRI data\")\n",
        "        print(f\"   Available columns: {list(df_train.columns)}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  MRI datasets not loaded. Run the previous cell first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Exploratory Data Analysis (EDA)\n",
        "\n",
        "**This section will be populated once you load your data. It will include:**\n",
        "- Dataset shape and basic information\n",
        "- Missing value analysis\n",
        "- Target variable distribution\n",
        "- Feature distributions and correlations\n",
        "- Demographic analysis\n",
        "- Cognitive assessment patterns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# EDA Functions - Ready to use once data is loaded\n",
        "\n",
        "def basic_data_info(df, df_name=\"Dataset\"):\n",
        "    \"\"\"Display basic information about the dataset\"\"\"\n",
        "    print(f\"üìä {df_name} Information:\")\n",
        "    print(f\"   Shape: {df.shape}\")\n",
        "    print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
        "    print(f\"   Columns: {list(df.columns)}\")\n",
        "    print(f\"   Data types:\\n{df.dtypes.value_counts()}\")\n",
        "    \n",
        "def missing_value_analysis(df):\n",
        "    \"\"\"Analyze missing values in the dataset\"\"\"\n",
        "    missing_data = df.isnull().sum()\n",
        "    missing_percent = (missing_data / len(df)) * 100\n",
        "    \n",
        "    missing_df = pd.DataFrame({\n",
        "        'Missing Count': missing_data,\n",
        "        'Missing Percentage': missing_percent\n",
        "    }).sort_values('Missing Percentage', ascending=False)\n",
        "    \n",
        "    # Only show columns with missing values\n",
        "    missing_df = missing_df[missing_df['Missing Count'] > 0]\n",
        "    \n",
        "    if len(missing_df) > 0:\n",
        "        print(\"üîç Missing Value Analysis:\")\n",
        "        print(missing_df)\n",
        "        \n",
        "        # Visualize missing values\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        sns.heatmap(df.isnull(), cbar=True, yticklabels=False)\n",
        "        plt.title('Missing Values Heatmap')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"‚úÖ No missing values found!\")\n",
        "\n",
        "def plot_target_distribution(df, target_col):\n",
        "    \"\"\"Plot distribution of target variable\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    # Count plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.countplot(data=df, x=target_col)\n",
        "    plt.title(f'Distribution of {target_col}')\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    # Pie chart\n",
        "    plt.subplot(1, 2, 2)\n",
        "    df[target_col].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
        "    plt.title(f'Proportion of {target_col}')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print statistics\n",
        "    print(f\"üìà {target_col} Distribution:\")\n",
        "    print(df[target_col].value_counts())\n",
        "    print(f\"\\nProportions:\")\n",
        "    print(df[target_col].value_counts(normalize=True))\n",
        "\n",
        "print(\"üîß EDA functions loaded and ready to use!\")\n",
        "print(\"üí° Uncomment the function calls below once you have loaded your data\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing\n",
        "\n",
        "**This section will include:**\n",
        "- Handling missing values\n",
        "- Feature engineering\n",
        "- Data normalization/scaling\n",
        "- Train-test split\n",
        "- Feature selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Preprocessing Functions\n",
        "\n",
        "def preprocess_data(df, target_col, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Comprehensive data preprocessing pipeline\n",
        "    \"\"\"\n",
        "    print(\"üîß Starting data preprocessing...\")\n",
        "    \n",
        "    # Create a copy to avoid modifying original data\n",
        "    df_processed = df.copy()\n",
        "    \n",
        "    # 1. Handle missing values\n",
        "    print(\"   üìù Handling missing values...\")\n",
        "    \n",
        "    # For numerical columns - fill with median\n",
        "    numerical_cols = df_processed.select_dtypes(include=[np.number]).columns\n",
        "    df_processed[numerical_cols] = df_processed[numerical_cols].fillna(df_processed[numerical_cols].median())\n",
        "    \n",
        "    # For categorical columns - fill with mode\n",
        "    categorical_cols = df_processed.select_dtypes(include=['object']).columns\n",
        "    for col in categorical_cols:\n",
        "        if col != target_col:  # Don't fill target column\n",
        "            df_processed[col] = df_processed[col].fillna(df_processed[col].mode()[0])\n",
        "    \n",
        "    # 2. Encode categorical variables\n",
        "    print(\"   üî§ Encoding categorical variables...\")\n",
        "    label_encoders = {}\n",
        "    for col in categorical_cols:\n",
        "        if col != target_col:\n",
        "            le = LabelEncoder()\n",
        "            df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
        "            label_encoders[col] = le\n",
        "    \n",
        "    # 3. Separate features and target\n",
        "    X = df_processed.drop(columns=[target_col])\n",
        "    y = df_processed[target_col]\n",
        "    \n",
        "    # 4. Train-test split\n",
        "    print(f\"   ‚úÇÔ∏è  Splitting data (test_size={test_size})...\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
        "    )\n",
        "    \n",
        "    # 5. Feature scaling\n",
        "    print(\"   üìè Scaling features...\")\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    # Convert back to DataFrames\n",
        "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)\n",
        "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
        "    \n",
        "    print(\"‚úÖ Data preprocessing completed!\")\n",
        "    print(f\"   Training set shape: {X_train_scaled.shape}\")\n",
        "    print(f\"   Test set shape: {X_test_scaled.shape}\")\n",
        "    \n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, label_encoders\n",
        "\n",
        "def feature_importance_analysis(X_train, y_train, feature_names=None):\n",
        "    \"\"\"\n",
        "    Analyze feature importance using Random Forest\n",
        "    \"\"\"\n",
        "    print(\"üå≤ Analyzing feature importance...\")\n",
        "    \n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf.fit(X_train, y_train)\n",
        "    \n",
        "    # Get feature importance\n",
        "    importance = rf.feature_importances_\n",
        "    \n",
        "    if feature_names is None:\n",
        "        feature_names = X_train.columns\n",
        "    \n",
        "    # Create importance DataFrame\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': feature_names,\n",
        "        'importance': importance\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    \n",
        "    # Plot feature importance\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.barplot(data=importance_df.head(20), x='importance', y='feature')\n",
        "    plt.title('Top 20 Feature Importance (Random Forest)')\n",
        "    plt.xlabel('Importance')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return importance_df\n",
        "\n",
        "print(\"üîß Preprocessing functions loaded and ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Machine Learning Models\n",
        "\n",
        "**This section will implement multiple ML models for comparison:**\n",
        "- Logistic Regression (baseline)\n",
        "- Random Forest\n",
        "- XGBoost\n",
        "- LightGBM\n",
        "- Support Vector Machine\n",
        "- Neural Network (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Machine Learning Model Pipeline\n",
        "\n",
        "def train_and_evaluate_models(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Train multiple models and compare their performance\n",
        "    \"\"\"\n",
        "    models = {\n",
        "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
        "        'LightGBM': lgb.LGBMClassifier(random_state=42, verbose=-1),\n",
        "        'SVM': SVC(random_state=42, probability=True)\n",
        "    }\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    print(\"ü§ñ Training and evaluating models...\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nüîÑ Training {name}...\")\n",
        "        \n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "        \n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
        "        \n",
        "        # Calculate metrics\n",
        "        accuracy = model.score(X_test, y_test)\n",
        "        auc_score = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
        "        \n",
        "        # Cross-validation score\n",
        "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "        \n",
        "        results[name] = {\n",
        "            'model': model,\n",
        "            'accuracy': accuracy,\n",
        "            'auc': auc_score,\n",
        "            'cv_mean': cv_scores.mean(),\n",
        "            'cv_std': cv_scores.std(),\n",
        "            'predictions': y_pred,\n",
        "            'probabilities': y_pred_proba\n",
        "        }\n",
        "        \n",
        "        print(f\"   ‚úÖ Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"   üìä AUC: {auc_score:.4f}\" if auc_score else \"   üìä AUC: N/A\")\n",
        "        print(f\"   üîÑ CV Score: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "def plot_model_comparison(results):\n",
        "    \"\"\"\n",
        "    Create comparison plots for all models\n",
        "    \"\"\"\n",
        "    # Extract metrics\n",
        "    model_names = list(results.keys())\n",
        "    accuracies = [results[name]['accuracy'] for name in model_names]\n",
        "    aucs = [results[name]['auc'] for name in model_names if results[name]['auc'] is not None]\n",
        "    cv_means = [results[name]['cv_mean'] for name in model_names]\n",
        "    cv_stds = [results[name]['cv_std'] for name in model_names]\n",
        "    \n",
        "    # Create subplots\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # Accuracy comparison\n",
        "    axes[0, 0].bar(model_names, accuracies, color='skyblue')\n",
        "    axes[0, 0].set_title('Model Accuracy Comparison')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # AUC comparison (only for models with probabilities)\n",
        "    auc_names = [name for name in model_names if results[name]['auc'] is not None]\n",
        "    if auc_names:\n",
        "        axes[0, 1].bar(auc_names, aucs, color='lightcoral')\n",
        "        axes[0, 1].set_title('Model AUC Comparison')\n",
        "        axes[0, 1].set_ylabel('AUC Score')\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Cross-validation scores\n",
        "    axes[1, 0].bar(model_names, cv_means, yerr=cv_stds, capsize=5, color='lightgreen')\n",
        "    axes[1, 0].set_title('Cross-Validation Scores')\n",
        "    axes[1, 0].set_ylabel('CV Score')\n",
        "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # ROC Curves\n",
        "    axes[1, 1].plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    for name in auc_names:\n",
        "        fpr, tpr, _ = roc_curve(y_test, results[name]['probabilities'])\n",
        "        axes[1, 1].plot(fpr, tpr, label=f'{name} (AUC={results[name][\"auc\"]:.3f})')\n",
        "    \n",
        "    axes[1, 1].set_xlabel('False Positive Rate')\n",
        "    axes[1, 1].set_ylabel('True Positive Rate')\n",
        "    axes[1, 1].set_title('ROC Curves')\n",
        "    axes[1, 1].legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def detailed_model_report(results, y_test):\n",
        "    \"\"\"\n",
        "    Generate detailed classification reports for all models\n",
        "    \"\"\"\n",
        "    print(\"\\nüìä DETAILED MODEL REPORTS\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    for name, result in results.items():\n",
        "        print(f\"\\nüîç {name.upper()}\")\n",
        "        print(\"-\" * 30)\n",
        "        print(classification_report(y_test, result['predictions']))\n",
        "        \n",
        "        # Confusion Matrix\n",
        "        cm = confusion_matrix(y_test, result['predictions'])\n",
        "        plt.figure(figsize=(6, 4))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.title(f'{name} - Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.show()\n",
        "\n",
        "print(\"ü§ñ ML model functions loaded and ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Interpretability & Feature Analysis\n",
        "\n",
        "**This section focuses on understanding what drives the predictions:**\n",
        "- SHAP values for model interpretability\n",
        "- Feature importance analysis\n",
        "- Partial dependence plots\n",
        "- Individual prediction explanations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model Interpretability Functions\n",
        "\n",
        "def shap_analysis(model, X_train, X_test, model_name=\"Model\"):\n",
        "    \"\"\"\n",
        "    Perform SHAP analysis for model interpretability\n",
        "    \"\"\"\n",
        "    print(f\"üîç Performing SHAP analysis for {model_name}...\")\n",
        "    \n",
        "    try:\n",
        "        # Create SHAP explainer\n",
        "        explainer = shap.TreeExplainer(model)\n",
        "        shap_values = explainer.shap_values(X_test)\n",
        "        \n",
        "        # Summary plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        shap.summary_plot(shap_values, X_test, show=False)\n",
        "        plt.title(f'{model_name} - SHAP Summary Plot')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Feature importance plot\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
        "        plt.title(f'{model_name} - SHAP Feature Importance')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        # Waterfall plot for first prediction\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        shap.waterfall_plot(explainer.expected_value, shap_values[0], X_test.iloc[0], show=False)\n",
        "        plt.title(f'{model_name} - SHAP Waterfall Plot (First Prediction)')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        return explainer, shap_values\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  SHAP analysis failed for {model_name}: {str(e)}\")\n",
        "        print(\"   This might be due to model type incompatibility\")\n",
        "        return None, None\n",
        "\n",
        "def feature_importance_comparison(models_dict, X_train):\n",
        "    \"\"\"\n",
        "    Compare feature importance across different models\n",
        "    \"\"\"\n",
        "    print(\"üìä Comparing feature importance across models...\")\n",
        "    \n",
        "    importance_data = []\n",
        "    \n",
        "    for name, model in models_dict.items():\n",
        "        if hasattr(model, 'feature_importances_'):\n",
        "            importance = model.feature_importances_\n",
        "            for i, feature in enumerate(X_train.columns):\n",
        "                importance_data.append({\n",
        "                    'model': name,\n",
        "                    'feature': feature,\n",
        "                    'importance': importance[i]\n",
        "                })\n",
        "    \n",
        "    if importance_data:\n",
        "        importance_df = pd.DataFrame(importance_data)\n",
        "        \n",
        "        # Create pivot table for comparison\n",
        "        pivot_df = importance_df.pivot(index='feature', columns='model', values='importance')\n",
        "        \n",
        "        # Plot comparison\n",
        "        plt.figure(figsize=(15, 10))\n",
        "        sns.heatmap(pivot_df, annot=True, fmt='.3f', cmap='YlOrRd')\n",
        "        plt.title('Feature Importance Comparison Across Models')\n",
        "        plt.xlabel('Models')\n",
        "        plt.ylabel('Features')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        \n",
        "        return importance_df\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No models with feature_importances_ found\")\n",
        "        return None\n",
        "\n",
        "def partial_dependence_analysis(model, X_train, feature_names, top_features=5):\n",
        "    \"\"\"\n",
        "    Create partial dependence plots for top features\n",
        "    \"\"\"\n",
        "    print(f\"üìà Creating partial dependence plots for top {top_features} features...\")\n",
        "    \n",
        "    # Get feature importance\n",
        "    if hasattr(model, 'feature_importances_'):\n",
        "        importance = model.feature_importances_\n",
        "        feature_importance = list(zip(feature_names, importance))\n",
        "        feature_importance.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_feature_names = [f[0] for f in feature_importance[:top_features]]\n",
        "    else:\n",
        "        # Use first few features if no importance available\n",
        "        top_feature_names = feature_names[:top_features]\n",
        "    \n",
        "    # Create partial dependence plots\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, feature in enumerate(top_feature_names):\n",
        "        if i < len(axes):\n",
        "            # Calculate partial dependence\n",
        "            from sklearn.inspection import partial_dependence\n",
        "            \n",
        "            try:\n",
        "                pd_result = partial_dependence(model, X_train, [feature])\n",
        "                \n",
        "                axes[i].plot(pd_result['values'][0], pd_result['average'][0])\n",
        "                axes[i].set_title(f'Partial Dependence: {feature}')\n",
        "                axes[i].set_xlabel(feature)\n",
        "                axes[i].set_ylabel('Partial Dependence')\n",
        "                axes[i].grid(True, alpha=0.3)\n",
        "            except Exception as e:\n",
        "                axes[i].text(0.5, 0.5, f'Error: {str(e)}', \n",
        "                           ha='center', va='center', transform=axes[i].transAxes)\n",
        "                axes[i].set_title(f'Error: {feature}')\n",
        "    \n",
        "    # Hide unused subplots\n",
        "    for i in range(len(top_feature_names), len(axes)):\n",
        "        axes[i].set_visible(False)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"üîç Interpretability functions loaded and ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Results Summary & Conclusions\n",
        "\n",
        "**This section will provide:**\n",
        "- Final model performance comparison\n",
        "- Key findings and insights\n",
        "- Clinical relevance of results\n",
        "- Recommendations for future work\n",
        "- Model deployment considerations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Results Summary and Model Selection\n",
        "\n",
        "def create_final_summary(results):\n",
        "    \"\"\"\n",
        "    Create a comprehensive summary of all model results\n",
        "    \"\"\"\n",
        "    print(\"üìã FINAL MODEL PERFORMANCE SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # Create summary DataFrame\n",
        "    summary_data = []\n",
        "    for name, result in results.items():\n",
        "        summary_data.append({\n",
        "            'Model': name,\n",
        "            'Accuracy': result['accuracy'],\n",
        "            'AUC': result['auc'] if result['auc'] is not None else 'N/A',\n",
        "            'CV_Mean': result['cv_mean'],\n",
        "            'CV_Std': result['cv_std']\n",
        "        })\n",
        "    \n",
        "    summary_df = pd.DataFrame(summary_data)\n",
        "    summary_df = summary_df.sort_values('Accuracy', ascending=False)\n",
        "    \n",
        "    print(summary_df.to_string(index=False))\n",
        "    \n",
        "    # Find best model\n",
        "    best_model_name = summary_df.iloc[0]['Model']\n",
        "    best_model = results[best_model_name]['model']\n",
        "    \n",
        "    print(f\"\\nüèÜ BEST PERFORMING MODEL: {best_model_name}\")\n",
        "    print(f\"   Accuracy: {summary_df.iloc[0]['Accuracy']:.4f}\")\n",
        "    print(f\"   AUC: {summary_df.iloc[0]['AUC']}\")\n",
        "    print(f\"   CV Score: {summary_df.iloc[0]['CV_Mean']:.4f} (¬±{summary_df.iloc[0]['CV_Std']:.4f})\")\n",
        "    \n",
        "    return best_model_name, best_model, summary_df\n",
        "\n",
        "def save_results(results, summary_df, output_dir=\"../results/\"):\n",
        "    \"\"\"\n",
        "    Save model results and summary to files\n",
        "    \"\"\"\n",
        "    import os\n",
        "    import joblib\n",
        "    from datetime import datetime\n",
        "    \n",
        "    # Create results directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    \n",
        "    # Save summary DataFrame\n",
        "    summary_df.to_csv(f\"{output_dir}model_summary_{timestamp}.csv\", index=False)\n",
        "    \n",
        "    # Save best model\n",
        "    best_model_name, best_model, _ = create_final_summary(results)\n",
        "    joblib.dump(best_model, f\"{output_dir}best_model_{timestamp}.pkl\")\n",
        "    \n",
        "    # Save all results\n",
        "    results_to_save = {}\n",
        "    for name, result in results.items():\n",
        "        results_to_save[name] = {\n",
        "            'accuracy': result['accuracy'],\n",
        "            'auc': result['auc'],\n",
        "            'cv_mean': result['cv_mean'],\n",
        "            'cv_std': result['cv_std']\n",
        "        }\n",
        "    \n",
        "    import json\n",
        "    with open(f\"{output_dir}all_results_{timestamp}.json\", 'w') as f:\n",
        "        json.dump(results_to_save, f, indent=2)\n",
        "    \n",
        "    print(f\"üíæ Results saved to {output_dir}\")\n",
        "    print(f\"   - Model summary: model_summary_{timestamp}.csv\")\n",
        "    print(f\"   - Best model: best_model_{timestamp}.pkl\")\n",
        "    print(f\"   - All results: all_results_{timestamp}.json\")\n",
        "\n",
        "def generate_insights_report(summary_df, feature_importance_df=None):\n",
        "    \"\"\"\n",
        "    Generate insights and recommendations based on results\n",
        "    \"\"\"\n",
        "    print(\"\\nüîç KEY INSIGHTS AND RECOMMENDATIONS\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Model performance insights\n",
        "    best_accuracy = summary_df.iloc[0]['Accuracy']\n",
        "    accuracy_range = summary_df['Accuracy'].max() - summary_df['Accuracy'].min()\n",
        "    \n",
        "    print(f\"üìä Model Performance:\")\n",
        "    print(f\"   ‚Ä¢ Best accuracy achieved: {best_accuracy:.4f}\")\n",
        "    print(f\"   ‚Ä¢ Performance range: {accuracy_range:.4f}\")\n",
        "    \n",
        "    if accuracy_range < 0.05:\n",
        "        print(f\"   ‚Ä¢ Models show consistent performance (low variance)\")\n",
        "    else:\n",
        "        print(f\"   ‚Ä¢ Significant performance differences between models\")\n",
        "    \n",
        "    # Feature importance insights\n",
        "    if feature_importance_df is not None:\n",
        "        top_features = feature_importance_df.head(10)\n",
        "        print(f\"\\nüéØ Top Contributing Features:\")\n",
        "        for idx, row in top_features.iterrows():\n",
        "            print(f\"   ‚Ä¢ {row['feature']}: {row['importance']:.4f}\")\n",
        "    \n",
        "    # Clinical recommendations\n",
        "    print(f\"\\nüè• Clinical Relevance:\")\n",
        "    if best_accuracy > 0.85:\n",
        "        print(f\"   ‚Ä¢ Strong predictive performance suggests clinical utility\")\n",
        "    elif best_accuracy > 0.75:\n",
        "        print(f\"   ‚Ä¢ Good predictive performance, suitable for screening\")\n",
        "    else:\n",
        "        print(f\"   ‚Ä¢ Moderate performance, may need additional features\")\n",
        "    \n",
        "    print(f\"\\nüî¨ Recommendations for Future Work:\")\n",
        "    print(f\"   ‚Ä¢ Collect additional biomarkers and cognitive assessments\")\n",
        "    print(f\"   ‚Ä¢ Implement longitudinal data collection\")\n",
        "    print(f\"   ‚Ä¢ Validate on independent datasets\")\n",
        "    print(f\"   ‚Ä¢ Consider ensemble methods for improved performance\")\n",
        "\n",
        "print(\"üìã Results summary functions loaded and ready!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Next Steps & Usage Instructions\n",
        "\n",
        "### üöÄ Getting Started\n",
        "\n",
        "1. **Download your datasets** and place them in the `../data/raw/` directory\n",
        "2. **Update the data loading section** (Section 1) with your actual file paths\n",
        "3. **Run the notebook cells sequentially** to perform the analysis\n",
        "4. **Customize the analysis** based on your specific dataset characteristics\n",
        "\n",
        "### üìù Customization Tips\n",
        "\n",
        "- **Target Variable**: Update the `target_col` parameter in preprocessing functions\n",
        "- **Feature Engineering**: Add domain-specific features in the preprocessing section\n",
        "- **Model Selection**: Modify the models dictionary to include/exclude specific algorithms\n",
        "- **Visualization**: Customize plots based on your data characteristics\n",
        "\n",
        "### üîß Troubleshooting\n",
        "\n",
        "- **Memory Issues**: Reduce dataset size or use data sampling for initial exploration\n",
        "- **Missing Libraries**: Install missing packages using `pip install -r requirements.txt`\n",
        "- **Data Format Issues**: Modify the data loading code based on your file format\n",
        "\n",
        "### üìä Expected Outputs\n",
        "\n",
        "- Comprehensive EDA visualizations\n",
        "- Model performance comparisons\n",
        "- Feature importance analysis\n",
        "- SHAP interpretability plots\n",
        "- Results saved to `../results/` directory\n",
        "\n",
        "---\n",
        "\n",
        "**Ready to analyze your Alzheimer's Disease data! üß†üî¨**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

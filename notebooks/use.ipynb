{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QNplJ9mcSHG","executionInfo":{"status":"ok","timestamp":1761413846655,"user_tz":420,"elapsed":28843,"user":{"displayName":"Ivan Habib","userId":"04809846432387072485"}},"outputId":"952b6d4d-0712-48fb-de22-c224c61b5d04"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Drive mounted.\n"]}],"source":["#see preprocessing note at top for schema.\n","#original data source\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import torch\n","from torch import nn\n","from google.colab import drive\n","import os\n","\n","drive_mounted = False\n","if not drive_mounted:\n","    drive.mount('/content/drive', force_remount=True)\n","    drive_mounted = True\n","    print(\"Drive mounted.\")\n","drive_path = \"/content/drive/MyDrive/Colab_Dev/ALZ_Variant\"\n"]},{"cell_type":"code","source":["# Get a list of all items in the directory\n","all_items = os.listdir(drive_path)\n","\n","# Filter out items that are not files or end with '.ipynb'\n","file_names = [item for item in all_items if os.path.isfile(os.path.join(drive_path, item)) and not item.endswith('.ipynb') and item.endswith('.npz')]\n","\n","print(\"List of filenames (excluding .ipynb):\")\n","for file_name in file_names:\n","    print(file_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U86Y4qo1cYmg","executionInfo":{"status":"ok","timestamp":1761413847973,"user_tz":420,"elapsed":1307,"user":{"displayName":"Ivan Habib","userId":"04809846432387072485"}},"outputId":"ea99a633-9e98-4d8a-e9fc-65befcf27d3d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["List of filenames (excluding .ipynb):\n","preprocessed_alz_data.npz\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"zwNUtPY6cp-d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1379cc0e"},"source":["# Task\n","Load the data from \"alz_data.npz\", split it into training and testing sets (x_train, x_test, y_train, y_test), and convert these arrays to PyTorch tensors."]},{"cell_type":"markdown","metadata":{"id":"270d8c5d"},"source":["## Load the data\n","\n","### Subtask:\n","Load the data from the `.npz` file using `np.load`.\n"]},{"cell_type":"markdown","metadata":{"id":"be375f8c"},"source":["**Reasoning**:\n","Construct the full file path and load the data from the .npz file using numpy.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"778529b2","executionInfo":{"status":"ok","timestamp":1761414002717,"user_tz":420,"elapsed":257,"user":{"displayName":"Ivan Habib","userId":"04809846432387072485"}},"outputId":"417d0ec7-4763-4a1d-807c-7a3f9cf12e05"},"source":["file_path = os.path.join(drive_path, \"preprocessed_alz_data.npz\")\n","loaded_data = np.load(file_path)\n","print(loaded_data.files)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['X_train', 'X_test', 'y_train', 'y_test']\n"]}]},{"cell_type":"markdown","metadata":{"id":"53bf3707"},"source":["## Extract features and labels\n","\n","### Subtask:\n","Extract the features (x) and labels (y) from the loaded data.\n"]},{"cell_type":"markdown","metadata":{"id":"020ddb34"},"source":["**Reasoning**:\n","Extract the features and labels from the loaded numpy arrays.\n","\n"]},{"cell_type":"code","metadata":{"id":"e5749068"},"source":["x_train_np = loaded_data['X_train']\n","x_test_np = loaded_data['X_test']\n","y_train_np = loaded_data['y_train']\n","y_test_np = loaded_data['y_test']"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f0932dd4"},"source":["## Convert to tensors\n","\n","### Subtask:\n","Convert the numpy arrays to PyTorch tensors.\n"]},{"cell_type":"markdown","metadata":{"id":"0675a9ec"},"source":["**Reasoning**:\n","Convert the numpy arrays to PyTorch tensors.\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1a098bb0","executionInfo":{"status":"ok","timestamp":1761414034553,"user_tz":420,"elapsed":87,"user":{"displayName":"Ivan Habib","userId":"04809846432387072485"}},"outputId":"2b8e0545-ad06-437a-9d60-d7f3a26e3850"},"source":["x_train = torch.from_numpy(x_train_np).float()\n","x_test = torch.from_numpy(x_test_np).float()\n","y_train = torch.from_numpy(y_train_np).long()\n","y_test = torch.from_numpy(y_test_np).long()\n","\n","print(\"x_train shape:\", x_train.shape)\n","print(\"x_test shape:\", x_test.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"y_test shape:\", y_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train shape: torch.Size([5076, 130])\n","x_test shape: torch.Size([1270, 130])\n","y_train shape: torch.Size([5076, 9])\n","y_test shape: torch.Size([1270, 9])\n"]}]},{"cell_type":"markdown","metadata":{"id":"12f5ce27"},"source":["## Summary:\n","\n","### Data Analysis Key Findings\n","\n","* The data was successfully loaded from the \"preprocessed_alz_data.npz\" file using `np.load()`.\n","* The loaded data contains the expected keys: 'X\\_train', 'X\\_test', 'y\\_train', and 'y\\_test'.\n","* The features and labels for both training and testing sets were extracted into NumPy arrays: `x_train_np`, `x_test_np`, `y_train_np`, and `y_test_np`.\n","* These NumPy arrays were successfully converted into PyTorch tensors: `x_train`, `x_test`, `y_train`, and `y_test`.\n","* The feature tensors (`x_train`, `x_test`) were cast to `float`, and the label tensors (`y_train`, `y_test`) were cast to `long`, which are suitable data types for numerical features and classification labels in PyTorch.\n","\n","### Insights or Next Steps\n","\n","* The data is now in the required PyTorch tensor format and is ready for use in a PyTorch model for training and evaluation.\n","* The next step would typically involve defining a PyTorch model architecture and proceeding with the training process using the prepared tensors.\n"]}]}